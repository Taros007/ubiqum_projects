{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agg_functions loaded!\n"
     ]
    }
   ],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import agg_functions # only works once in Jupyter notebook after restart kernel. Using magic line instead\n",
    "%run agg_functions.py\n",
    "\n",
    "#Set seed\n",
    "RSEED = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "app_train = pd.read_csv('../input/application_train.csv').replace({365243: np.nan})\n",
    "app_test = pd.read_csv('../input/application_test.csv').replace({365243: np.nan})\n",
    "\n",
    "train_ids = list(app_train['SK_ID_CURR'])\n",
    "test_ids = list(app_test['SK_ID_CURR'])\n",
    "\n",
    "# One Hot Encode\n",
    "app_train, app_test = pd.get_dummies(app_train), pd.get_dummies(app_test)\n",
    "app_test['TARGET'] = np.nan\n",
    "\n",
    "# Align on the columns\n",
    "app_train, app_test = app_train.align(app_test, axis = 1, join = 'inner')\n",
    "\n",
    "original_features = list(app_train.columns)\n",
    "original_features.remove('TARGET')\n",
    "original_features.remove('SK_ID_CURR')\n",
    "\n",
    "# Combine train/test into one dataset\n",
    "app = app_train.append(app_test, sort=False)\n",
    "\n",
    "#We join the training and testing data\n",
    "#together to make sure that any operations we do to one set \n",
    "#is repeated for the other set. \n",
    "#The testing data can be extracted using \n",
    "#test = app[app[\"TARGET\"].isnull()].copy()\n",
    "#and the training data by\n",
    "#train = app[app['TARGET'].notnull()].copy()\n",
    "                                                                \n",
    "# Extract the training and testing data\n",
    "#app_new_train, app_new_test = app[app['TARGET'].notnull()], app[app['TARGET'].isnull()]\n",
    "\n",
    "\n",
    "#app_train = pd.read_csv('../input/application_train.csv').replace({365243: np.nan})\n",
    "#app_test = pd.read_csv('../input/application_test.csv').replace({365243: np.nan})\n",
    "#bureau = pd.read_csv('../input/bureau.csv').replace({365243: np.nan})\n",
    "#bureau_balance = pd.read_csv('../input/bureau_balance.csv').replace({365243: np.nan})\n",
    "#cash = pd.read_csv('../input/POS_CASH_balance.csv').replace({365243: np.nan})\n",
    "#credit = pd.read_csv('../input/credit_card_balance.csv').replace({365243: np.nan})\n",
    "#previous = pd.read_csv('../input/previous_application.csv').replace({365243: np.nan})\n",
    "#installments = pd.read_csv('../input/installments_payments.csv').replace({365243: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau = pd.read_csv('../input/bureau.csv')\n",
    "bureau_info = agg_child(bureau, 'SK_ID_CURR', 'BUREAU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous = pd.read_csv('../input/previous_application.csv')\n",
    "previous_info = agg_child(previous, 'SK_ID_CURR', 'PREVIOUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance = pd.read_csv('../input/bureau_balance.csv')\n",
    "bureau_balance_info = agg_grandchild(bureau_balance, bureau, 'SK_ID_BUREAU', 'SK_ID_CURR', 'BB')\n",
    "del bureau_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card = pd.read_csv('../input/credit_card_balance.csv')\n",
    "credit_card_info = agg_grandchild(credit_card, previous, 'SK_ID_PREV', 'SK_ID_CURR', 'CC')\n",
    "del credit_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash = pd.read_csv('../input/POS_CASH_balance.csv')\n",
    "cash_info = agg_grandchild(cash, previous, 'SK_ID_PREV', 'SK_ID_CURR', 'CASH')\n",
    "del cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments = pd.read_csv('../input/installments_payments.csv')\n",
    "installments_info = agg_grandchild(installments, previous, 'SK_ID_PREV', 'SK_ID_CURR', 'IN')\n",
    "del installments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.enable()\n",
    "del bureau, previous\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge everything into train dataframe\n",
    "app_train = app_train.set_index('SK_ID_CURR')\n",
    "app_test = app_test.set_index('SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = app_train.merge(bureau_info, on = 'SK_ID_CURR', how = 'left')\n",
    "app_test = app_test.merge(bureau_info, on = 'SK_ID_CURR', how = 'left')\n",
    "del bureau_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = app_train.merge(previous_info, on = 'SK_ID_CURR', how = 'left')\n",
    "app_test = app_test.merge(previous_info, on = 'SK_ID_CURR', how = 'left')\n",
    "del previous_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = app_train.merge(bureau_balance_info, on = 'SK_ID_CURR', how = 'left')\n",
    "app_test = app_test.merge(bureau_balance_info, on = 'SK_ID_CURR', how = 'left')\n",
    "del bureau_balance_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = app_train.merge(credit_card_info, on = 'SK_ID_CURR', how = 'left')\n",
    "app_test = app_test.merge(credit_card_info, on = 'SK_ID_CURR', how = 'left')\n",
    "del credit_card_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = app_train.merge(cash_info, on = 'SK_ID_CURR', how = 'left')\n",
    "app_test = app_test.merge(cash_info, on = 'SK_ID_CURR', how = 'left')\n",
    "del cash_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = app_train.merge(installments_info, on = 'SK_ID_CURR', how = 'left')\n",
    "app_test = app_test.merge(installments_info, on = 'SK_ID_CURR', how = 'left')\n",
    "del installments_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for columns with duplicated values\n",
    "#_, idx = np.unique(app_train, axis = 1, return_index = True)\n",
    "#print('There are {} columns with all duplicated values.'.format(app.shape[1] - len(idx)))\n",
    "\n",
    "#_, idx = np.unique(app_test, axis = 1, return_index = True)\n",
    "#print('There are {} columns with all duplicated values.'.format(app.shape[1] - len(idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app_train.reset_index(inplace=True)\n",
    "app_test.reset_index(inplace=True)\n",
    "\n",
    "app_train.to_csv('../input/app_train_inprogress.csv', index = False)\n",
    "app_test.to_csv('../input/app_test_inprogress.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = pd.read_csv('../input/app_train_inprogress.csv')\n",
    "app_test = pd.read_csv('../input/app_test_inprogress.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 1417)\n",
      "(48744, 1417)\n"
     ]
    }
   ],
   "source": [
    "print(app_train.shape)\n",
    "print(app_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = list(app_train['SK_ID_CURR'])\n",
    "test_ids = list(app_test['SK_ID_CURR'])\n",
    "\n",
    "# One Hot Encode\n",
    "app_train, app_test = pd.get_dummies(app_train), pd.get_dummies(app_test)\n",
    "\n",
    "# Add nan-target variable to test in order to be able to align\n",
    "app_test['TARGET'] = np.nan\n",
    "\n",
    "# Align on the columns\n",
    "app_train, app_test = app_train.align(app_test, axis = 1, join = 'inner')\n",
    "\n",
    "original_features = list(app_train.columns)\n",
    "original_features.remove('TARGET')\n",
    "original_features.remove('SK_ID_CURR')\n",
    "\n",
    "# Combine train/test into one dataset\n",
    "app = app_train.append(app_test, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(app_train, app_train[\"TARGET\"]):\n",
    "    print(train_index, test_index)\n",
    "    strat_train_set = app_train.loc[train_index]\n",
    "    strat_test_set = app_train.loc[test_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "def cross_validate(train):\n",
    "    \"\"\"Compute cross validation ROC AUC of a gradient boosting model for a given training dataset\"\"\"\n",
    "    \n",
    "    # Extract the labels\n",
    "    train_labels = np.array(train['TARGET'].astype(np.int32)).reshape((-1, ))\n",
    "    train = train.drop(columns = ['TARGET', 'SK_ID_CURR'])\n",
    "\n",
    "    # Create a  lgb training set\n",
    "    train_set = lgb.Dataset(train, label = train_labels)\n",
    "\n",
    "    # Find default hyperparameters\n",
    "    model = lgb.LGBMClassifier()\n",
    "    params = model.get_params()\n",
    "\n",
    "    # Number of estimators will be selected through early stopping\n",
    "    del params['n_estimators'], params['silent']\n",
    "\n",
    "    # Early stoppping with 5 fold cross validation\n",
    "    cv_results = lgb.cv(params, train_set, num_boost_round = 10000, metrics = 'auc', \n",
    "                        early_stopping_rounds = 100, seed = RSEED, nfold = 5)\n",
    "\n",
    "    print('Cross Validation ROC AUC: {:.5f} with std: {:.5f}.'.format(cv_results['auc-mean'][-1],\n",
    "                                                                               cv_results['auc-stdv'][-1]))\n",
    "\n",
    "    print('Number of estimators trained: {}'.format(len(cv_results['auc-mean'])))\n",
    "    \n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_baseline = cross_validate(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_verification(cv_results, train, test):\n",
    "    \n",
    "    # Extract the labels\n",
    "    train_labels = np.array(train['TARGET'].astype(np.int32)).reshape((-1, ))\n",
    "    train = train.drop(columns = ['TARGET', 'SK_ID_CURR'])\n",
    "    test_ids = list(test['SK_ID_CURR'])\n",
    "    test_target = test[\"TARGET\"]\n",
    "    test = test.drop(columns = ['TARGET', 'SK_ID_CURR']) \n",
    "    \n",
    "    # Make model with optimal number of estimators and train on training data\n",
    "    model = lgb.LGBMClassifier(n_estimators = len(cv_results['auc-mean']), random_state=RSEED)\n",
    "    model.fit(train, train_labels)\n",
    "    \n",
    "    # Make predictions on the testing data\n",
    "    prob = model.predict_proba(test)[:, 1]\n",
    "    preds = prob.round()\n",
    "    test_predictions = pd.DataFrame({'SK_ID_CURR': test_ids, \n",
    "                                'TARGET': test_target,\n",
    "                                'PREDICTION': preds,\n",
    "                                'PROBABILITY': prob})\n",
    "    return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_verification(cv_results_baseline, strat_train_set, strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# Compute Precision-Recall and plot curve\n",
    "precision, recall, thresholds = precision_recall_curve(results[\"TARGET\"], results[\"PROBABILITY\"])\n",
    "area = auc(recall, precision)\n",
    "print(\"Area Under PR Curve(AP): %0.2f\" % area)  #should be same as AP?\n",
    "\n",
    "print('AP', average_precision_score(results[\"TARGET\"], results[\"PROBABILITY\"], average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create submission file for Kaggle\n",
    "submission_baseline = kaggle_submission(cv_results_baseline, app_train, app_test)\n",
    "submission_baseline.to_csv('../input/submission_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agg_functions as agg\n",
    "agg.hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
