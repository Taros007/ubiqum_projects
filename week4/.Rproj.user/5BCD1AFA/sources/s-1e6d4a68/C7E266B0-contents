
#Prepare clusters to optimze computing time
library(doParallel)
cl <- makeCluster(3)
registerDoParallel(cl)

#Import dataset
library(readr)
surveyData = read.csv('./input/CompleteResponses.csv')

#Transform variables
surveyData$elevel <- as.factor(surveyData$elevel)
surveyData$car <- as.factor(surveyData$car)
surveyData$zipcode <- as.factor(surveyData$zipcode)
surveyData$brand <- factor(surveyData$brand, 
                              levels = c(0,1),
                              labels = c("Acer", "Sony"))

######EDA##### [to be commented out later]
library(tidyverse)
library(caret)
library(e1071)
str(surveyData)
summary(surveyData)

#no NAs found

# ##Explore variation
# #First categoricals and ordinals
# ggplot(surveyData) + geom_bar(mapping = aes(x = surveyData$elevel))
# ggplot(surveyData) + geom_bar(mapping = aes(x = surveyData$car))
# ggplot(surveyData) + geom_bar(mapping = aes(x = surveyData$zipcode))
# ggplot(surveyData) + geom_bar(mapping = aes(x = surveyData$brand))
# #Next, numerical
# ggplot(surveyData) + geom_histogram(mapping = aes(x = surveyData$salary))
# ggplot(surveyData) + geom_histogram(mapping = aes(x = surveyData$age))
# ggplot(surveyData) + geom_histogram(mapping = aes(x = surveyData$credit))
##FINDING: most variables have normal variance. No extreme attribute values (outliers)
#Exceptions: brand (many more 1), and two high occurances for age

# ##Explore collinearity and correlation
# library(corrplot)
# corrplot(cor(base::Filter(is.numeric, surveyData)))
# ##No collinearity and correlation between numeric variables
# 
# #Second for categorical and ordinals - vs salary
# ggplot(surveyData) + geom_boxplot(mapping = aes(x = reorder(car, salary, FUN = median), y = salary))
# ggplot(surveyData) + geom_boxplot(mapping = aes(x = reorder(zipcode, salary, FUN = median), y = salary))
# ggplot(surveyData) + geom_boxplot(mapping = aes(x = reorder(elevel, salary, FUN = median), y = salary))
# 

# ##Explore relations between independent and dependent variable
# #Ordinal and categorical variables first
# ggplot(data = surveyData) + geom_count(mapping = aes(x = car, y = brand))
# ggplot(data = surveyData) + geom_count(mapping = aes(x = zipcode, y = brand))
# ggplot(data = surveyData) + geom_count(mapping = aes(x = elevel, y = brand))
# 
# ggplot(surveyData) + geom_boxplot(mapping = aes(x = reorder(brand, salary, FUN = median), y = salary))
# ggplot(surveyData) + geom_boxplot(mapping = aes(x = reorder(salary, age, FUN = median), y = age))
# ggplot(surveyData) + geom_boxplot(mapping = aes(x = reorder(brand, credit, FUN = median), y = credit))
# ##FINDING: brand 1 is being bought by people with higher salaries

#MAKE SCATTER PLOT AGE, SALARY with colors for brand

#Create training and test set with 75%
set.seed(998)
inTraining <- createDataPartition(surveyData$brand, p = .75, list = FALSE)
training <- surveyData[inTraining,]
testing <- surveyData[-inTraining,]

#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1, sampling = "up", classProbs = TRUE)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
rfFit1 <- train(brand~., data = training, method = "rf", preProcess = c("center"), trControl=fitControl, metric = "Kappa")

#Predict
predictions <- predict(rfFit1, testing)
confusionMatrix(predictions, testing$brand)

postResample(predictions, surveyData)

#Try to solve class imbalance
summary(surveyData$brand)

#Save model to avoid future retraining
saveRDS(rfFit1, './output/RF.rds')

#Load model again
rfFit1 <- readRDS('./output/RF.rds')

# Stop Cluster. 
stopCluster(cl)                   
